{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jonathan-Oviedo/ML-23-TEA/blob/Labs/ImageClassificationProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification Project\n",
        "By: Jonathan Oviedo and Gerald Atilus\n",
        "\n",
        "The work done for this project was done in collaboration with each member contributing an equal amount of work for each section, so the work was just added to one collab.\n",
        "\n"
      ],
      "metadata": {
        "id": "IYhf9hzaBv2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observe/Read the data"
      ],
      "metadata": {
        "id": "9Q-FfF6jDuNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing our two used libraries keras and train test split"
      ],
      "metadata": {
        "id": "ZzKwlvqADyHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "_yEpAHXDs3Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading CIFAR dataset to their variables"
      ],
      "metadata": {
        "id": "On-u6qEBDLio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset and assign to variables for testing and training\n",
        "(trainImages, trainLabels), (testImages, testLabels) = keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "sOwqKKtLtLvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe each variable by printing them out."
      ],
      "metadata": {
        "id": "B_zxowRQDm2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#printing out train labels and images\n",
        "print(\"trainImages:\", trainImages.shape)\n",
        "print(\"trainLabels:\", trainLabels.shape)\n",
        "#printing out test labels and images\n",
        "print(\"testImages:\", testImages.shape)\n",
        "print(\"testLabels:\", testLabels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6bBDLyTD-bb",
        "outputId": "9113e9d8-d3eb-4c1d-bc82-719e129d6cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainImages: (50000, 32, 32, 3)\n",
            "trainLabels: (50000, 1)\n",
            "testImages: (10000, 32, 32, 3)\n",
            "testLabels: (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data has 50,000 images of the shape 32,32,3"
      ],
      "metadata": {
        "id": "k1WOweh2Yxsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing data has 10,000 images of shape 32,32,3"
      ],
      "metadata": {
        "id": "BtyBrN29HUoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "labels only have a single column which is the label of the image"
      ],
      "metadata": {
        "id": "pbEAujBeHfKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting and modifying the Data"
      ],
      "metadata": {
        "id": "ZvFR_4qiGgeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting and training the data"
      ],
      "metadata": {
        "id": "afe6C2OvEqOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training data into training and validation sets.\n",
        "#using 80% in training and 20% in val sets\n",
        "trainImages, valImages, trainLabels, valLabels = train_test_split(\n",
        "    trainImages, trainLabels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tSWVzQ1ltN3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of trainImage\n"
      ],
      "metadata": {
        "id": "WxFDrNdsQzaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#used to look for shape of train image\n",
        "trainImages.shape"
      ],
      "metadata": {
        "id": "vze1rWXNQ_h2",
        "outputId": "ed6552af-16c0-4a2f-915d-abd6ce1ac1f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "added valimages to seperate line since it caused issues when looking into train image's shape"
      ],
      "metadata": {
        "id": "W_pdcFCeONp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#used to look for shape of val sets\n",
        "valImages.shape"
      ],
      "metadata": {
        "id": "sIqZiNjKOI60",
        "outputId": "cbed0de7-2dc0-4170-f145-2b172ee01ec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like the training  and testing shapes previously, train and val images returned 50,000 and 10,000 images respectively"
      ],
      "metadata": {
        "id": "dH-mPnDUYoLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize the pixel value"
      ],
      "metadata": {
        "id": "wYfXHh8BOwmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use trainImages/255 and testImages/255 so that the pixel values are normalized to 0-1 instead of 0-255"
      ],
      "metadata": {
        "id": "mkGdHafYRRcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1 for training and testing images\n",
        "trainImages, testImages = trainImages / 255., testImages / 255."
      ],
      "metadata": {
        "id": "6Tg3ArzjFBqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize validation images\n",
        "val_images = valImages / 255."
      ],
      "metadata": {
        "id": "pdejawAYGGeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the CNN using keras."
      ],
      "metadata": {
        "id": "xKmzM0JHHRKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating keras model"
      ],
      "metadata": {
        "id": "GaT84uLgHXB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating keras model\n",
        "model = keras.Sequential([\n",
        "#layer with 32 filters, each of size 3x3. \n",
        "#we went with relu instead of sigmoid after some testing and found it to give a better result though this \n",
        "#could be an issue on our own end.\n",
        "  keras.layers.Conv2D(32, kernel_size=(3,3) ,  activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "    \n",
        "# max pool layer created of size 2x2 to reduce the dimension of the previous layers\n",
        " keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "#same as above instead using 64 filters and once again using relu instead of sigmoid\n",
        " keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"),\n",
        "    \n",
        "#same as the previous pool layer created\n",
        " keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "# takes the output from the layers above and puts it into 1D.\n",
        " keras.layers.Flatten(),\n",
        "    \n",
        "# creating connected layer with 64 units, using relu\n",
        " keras.layers.Dense(64, activation=\"relu\"),\n",
        "    \n",
        "# create another layer with 10 units for the classes previously established\n",
        " keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "\n",
        "# summarize the created model to display the parameters of each layer created\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "31srW9wGtQ7X",
        "outputId": "cf8f7e6a-7eb2-4e6f-e55d-bd50b6793a3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                147520    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167,562\n",
            "Trainable params: 167,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# compiling the model we created"
      ],
      "metadata": {
        "id": "UybGzX-jOh6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for compiling the model we attempted two different types of SparceCategoricalCrossentropy we chose this method due to finding that multi class classification tasks is best suited for SCC."
      ],
      "metadata": {
        "id": "dAIKDWZJOk4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the optimizer we attempted two SGD and RMS we found that RMS gave a better accuracy by about 6%"
      ],
      "metadata": {
        "id": "0bXsBFpqZUYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the SGD optimizer\n",
        "#sgd_optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "#model.compile(optimizer=sgd_optimizer,\n",
        " #             loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  #            metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Compile the model with the RMSprop optimizer\n",
        "rmsprop_optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer=rmsprop_optimizer,\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])  "
      ],
      "metadata": {
        "id": "-TJ_lHCp7fDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting the created Model"
      ],
      "metadata": {
        "id": "1z_puCT_Rh2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we fit the model. We tried a different number of epochs and found that 10 epochs gave our best result.\n",
        "5 epochs returned 65%, 15 epochs returned 62% and 10 epochs returned around 67%"
      ],
      "metadata": {
        "id": "6Vp-n-rwTzUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model using 10 epochs\n",
        "hist = model.fit(trainImages, trainLabels, validation_data=(valImages, valLabels), epochs=10, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9nZoz-QPKY3",
        "outputId": "33127fe7-c572-4692-9afe-3023e02a894e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 1s 10ms/step - loss: 0.8815 - accuracy: 0.6957 - val_loss: 176.6707 - val_accuracy: 0.5451\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.8399 - accuracy: 0.7097 - val_loss: 179.9561 - val_accuracy: 0.5331\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.8029 - accuracy: 0.7223 - val_loss: 246.7264 - val_accuracy: 0.4861\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7722 - accuracy: 0.7340 - val_loss: 186.6096 - val_accuracy: 0.5530\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7347 - accuracy: 0.7481 - val_loss: 194.8896 - val_accuracy: 0.5477\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7049 - accuracy: 0.7577 - val_loss: 234.4758 - val_accuracy: 0.5184\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6740 - accuracy: 0.7679 - val_loss: 214.6334 - val_accuracy: 0.5364\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.6422 - accuracy: 0.7808 - val_loss: 235.5895 - val_accuracy: 0.5308\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6154 - accuracy: 0.7891 - val_loss: 318.3051 - val_accuracy: 0.4603\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.5866 - accuracy: 0.7980 - val_loss: 235.3861 - val_accuracy: 0.5405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the model accuracy"
      ],
      "metadata": {
        "id": "cGZ4tgryRjjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setting/getting the model's accuracy\n",
        "Accuracy = model.evaluate(testImages, testLabels)\n",
        "\n",
        "# Print the accuracy score\n",
        "print(\"Accuracy: \", Accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3enxLHVtTz_",
        "outputId": "7d1de679-d933-4757-abec-08033e2a1373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0111 - accuracy: 0.6720\n",
            "Accuracy:  0.671999990940094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were able to achieve a 67.2% accuracy score on our test data, which was the best score we were able to get when tweaking the model compile. Other attempts usually returned 55-60 so we found that our current implementation was the best we could attempt with our current setup."
      ],
      "metadata": {
        "id": "-YOs2tRqW6S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are content with our results and believe that a better methodology could probably yield a better result, but also found that a change in SCC type could also improve the accuracy score"
      ],
      "metadata": {
        "id": "OR4kAiGPb9aC"
      }
    }
  ]
}